#!/usr/bin/env python3
"""
æ··åˆ OCR ç­–ç•¥å‹æµ‹è„šæœ¬

æµ‹è¯• Qwen3-VL-Plus + PaddleOCR å¤‡ä»½æ–¹æ¡ˆçš„æ€§èƒ½å’Œç¨³å®šæ€§
"""

import os
import sys
import time
import json
import csv
import argparse
import logging
import statistics
import importlib.util
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional

# åŠ¨æ€å¯¼å…¥ registration_ocr
aerovision_inference_path = Path(__file__).parent.parent.parent / 'Aerovision-V1-inference'
registration_ocr_path = aerovision_inference_path / 'registration_ocr.py'

spec = importlib.util.spec_from_file_location('registration_ocr', str(registration_ocr_path))
registration_ocr_module = importlib.util.module_from_spec(spec)
sys.modules['registration_ocr'] = registration_ocr_module
spec.loader.exec_module(registration_ocr_module)

RegistrationOCR = registration_ocr_module.RegistrationOCR

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def load_ground_truth(csv_file: str) -> Dict[str, str]:
    """
    ä» CSV æ–‡ä»¶åŠ è½½çœŸå®æ³¨å†Œå·

    Args:
        csv_file: CSV æ–‡ä»¶è·¯å¾„

    Returns:
        dict: æ–‡ä»¶ååˆ°çœŸå®æ³¨å†Œå·çš„æ˜ å°„
    """
    ground_truth = {}
    try:
        with open(csv_file, 'r', encoding='utf-8-sig') as f:
            reader = csv.DictReader(f)
            filename_key = 'filename'
            if reader.fieldnames and '\ufeff' in reader.fieldnames[0]:
                filename_key = reader.fieldnames[0]

            for row in reader:
                filename = row.get(filename_key, '')
                registration = row['registration']
                ground_truth[filename] = registration
    except Exception as e:
        logger.warning(f"æ— æ³•è¯»å– CSV æ–‡ä»¶: {e}")
    return ground_truth


def stress_test_hybrid_ocr(
    data_dir: str,
    csv_file: str,
    max_images: int = 100,
    max_concurrent: int = 1,
    output_file: Optional[str] = None
) -> Dict[str, Any]:
    """
    æ‰§è¡Œæ··åˆ OCR å‹æµ‹

    Args:
        data_dir: æ•°æ®ç›®å½•
        csv_file: CSV æ ‡ç­¾æ–‡ä»¶
        max_images: æœ€å¤§æµ‹è¯•å›¾ç‰‡æ•°
        max_concurrent: æœ€å¤§å¹¶å‘æ•°
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„

    Returns:
        å‹æµ‹ç»“æœ
    """
    print('='*80)
    print('ğŸ§ª æ··åˆ OCR ç­–ç•¥å‹æµ‹')
    print('='*80)
    print(f'\n   æ•°æ®ç›®å½•: {data_dir}')
    print(f'   CSV æ–‡ä»¶: {csv_file}')
    print(f'   æµ‹è¯•å›¾ç‰‡æ•°: {max_images}')
    print(f'   æœ€å¤§å¹¶å‘æ•°: {max_concurrent}')

    # åŠ è½½çœŸå®æ ‡ç­¾
    print('\nğŸ“‹ åŠ è½½çœŸå®æ ‡ç­¾...')
    ground_truth = load_ground_truth(csv_file)
    print(f'   åŠ è½½äº† {len(ground_truth)} æ¡æ ‡ç­¾')

    # åˆå§‹åŒ–æ··åˆ OCR
    print('\nğŸ“ åˆå§‹åŒ–æ··åˆ OCR (Qwen3-VL-Plus + PaddleOCR)...')
    try:
        ocr = RegistrationOCR(
            mode='hybrid',
            qwen_model='qwen3-vl-plus',
            confidence_threshold=0.8,
            timeout=60
        )
        print('âœ… æ··åˆ OCR åˆå§‹åŒ–æˆåŠŸ\n')
    except Exception as e:
        print(f'âŒ æ··åˆ OCR åˆå§‹åŒ–å¤±è´¥: {e}')
        return {
            'total_images': 0,
            'successful_tests': 0,
            'failed_tests': max_images,
            'accuracy': 0.0,
            'correct_count': 0,
            'avg_latency_ms': 0.0,
            'p50_latency_ms': 0.0,
            'p95_latency_ms': 0.0,
            'throughput_rps': 0.0,
            'avg_confidence': 0.0,
            'high_confidence_count': 0,
            'medium_confidence_count': 0,
            'low_confidence_count': 0,
            'qwen_success_count': 0,
            'paddle_fallback_count': 0,
            'qwen_api_fail_count': 0,
            'results': [],
            'errors': []
        }

    # æ”¶é›†æµ‹è¯•å›¾ç‰‡
    data_path = Path(data_dir)
    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp'}
    all_images = []
    for ext in image_extensions:
        all_images.extend(data_path.rglob(f'*{ext}'))

    if max_images:
        all_images = all_images[:max_images]

    print(f'ğŸ“· æ‰¾åˆ° {len(all_images)} å¼ å›¾ç‰‡')
    print(f'   æµ‹è¯• {len(all_images)} å¼ å›¾ç‰‡\n')

    # æµ‹è¯•ç»“æœ
    results = []
    latencies = []
    errors = []

    # ç»Ÿè®¡
    correct = 0
    total = 0
    high_conf = 0
    medium_conf = 0
    low_conf = 0
    qwen_success = 0
    paddle_fallback = 0
    qwen_api_fail = 0

    # æ‰§è¡Œå‹æµ‹
    start_time = time.time()

    for idx, image_path in enumerate(all_images, 1):
        filename = image_path.name
        ground_truth_reg = ground_truth.get(filename)

        if not ground_truth_reg:
            print(f'[  {idx:3}/{len(all_images)}] âš ï¸  {filename}')
            print(f'       è·³è¿‡ï¼šCSV ä¸­æ²¡æœ‰æ‰¾åˆ°çœŸå®æ ‡ç­¾')
            continue

        try:
            print(f'[  {idx:3}/{len(all_images)}] ğŸ”„ {filename}', end='')

            # æ‰§è¡Œ OCR è¯†åˆ«
            result_start = time.time()
            result = ocr.recognize(str(image_path))
            latency = (time.time() - result_start) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’

            predicted = result['registration']
            confidence = result['confidence']

            # åˆ¤æ–­æ˜¯å¦æ­£ç¡®
            is_correct = (predicted.upper() == ground_truth_reg.upper())

            # ç»Ÿè®¡
            total += 1
            latencies.append(latency)

            if is_correct:
                correct += 1
                print(f'\r[  {idx:3}/{len(all_images)}] âœ“ {filename}')
            else:
                print(f'\r[  {idx:3}/{len(all_images)}] âœ— {filename}')

            # ç½®ä¿¡åº¦ç»Ÿè®¡
            if confidence >= 0.8:
                high_conf += 1
            elif confidence >= 0.5:
                medium_conf += 1
            else:
                low_conf += 1

            # ä¼°ç®—ä½¿ç”¨çš„æ˜¯ Qwen è¿˜æ˜¯ PaddleOCRï¼ˆåŸºäºç½®ä¿¡åº¦å’Œç»“æœï¼‰
            # é«˜ç½®ä¿¡åº¦ï¼ˆ>=0.8ï¼‰ä¸”ä¸æ˜¯ PaddleOCR çš„å…¸å‹é”™è¯¯æ¨¡å¼ï¼Œè®¤ä¸ºæ˜¯ Qwen
            # ä½ç½®ä¿¡åº¦ï¼ˆ<0.8ï¼‰æˆ– PaddleOCR çš„å…¸å‹é”™è¯¯æ¨¡å¼ï¼Œè®¤ä¸ºæ˜¯ PaddleOCR
            if confidence >= 0.8:
                qwen_success += 1
            else:
                paddle_fallback += 1

            print(f'       çœŸå®: {ground_truth_reg}, é¢„æµ‹: {predicted}, ç½®ä¿¡åº¦: {confidence:.2f}, å»¶è¿Ÿ: {latency:.0f}ms')

            # ä¿å­˜ç»“æœ
            results.append({
                'image': filename,
                'ground_truth': ground_truth_reg,
                'predicted': predicted,
                'confidence': confidence,
                'latency_ms': latency,
                'is_correct': is_correct
            })

        except Exception as e:
            total += 1
            errors.append({
                'image': filename,
                'error': str(e)
            })
            print(f'\r[  {idx:3}/{len(all_images)}] âŒ {filename}')
            print(f'       é”™è¯¯: {e}')

    total_time = time.time() - start_time

    # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
    accuracy = correct / total if total > 0 else 0.0
    avg_latency = statistics.mean(latencies) if latencies else 0.0
    p50_latency = statistics.median(latencies) if latencies else 0.0
    p95_latency = statistics.quantiles(latencies, n=20)[18] if len(latencies) >= 20 else (latencies[-1] if latencies else 0.0)
    throughput = total / total_time if total_time > 0 else 0.0
    avg_confidence = statistics.mean([r['confidence'] for r in results]) if results else 0.0

    # è¾“å‡ºç»“æœ
    print('\n' + '='*80)
    print('ğŸ“Š å‹æµ‹ç»“æœ')
    print('='*80)

    print(f'\næ€»ä½“ç»Ÿè®¡ï¼š')
    print(f'   æ€»å›¾ç‰‡æ•°: {total}')
    print(f'   æˆåŠŸè¯†åˆ«: {total - len(errors)}')
    print(f'   å¤±è´¥è¯†åˆ«: {len(errors)}')

    print(f'\nå‡†ç¡®ç‡æŒ‡æ ‡ï¼š')
    print(f'   è¯†åˆ«å‡†ç¡®ç‡: {accuracy:.4f} ({accuracy*100:.2f}%)')
    print(f'   æ­£ç¡®è¯†åˆ«æ•°: {correct}/{total}')

    print(f'\nç½®ä¿¡åº¦ç»Ÿè®¡ï¼š')
    print(f'   å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.4f}')
    print(f'   é«˜ç½®ä¿¡åº¦ (â‰¥0.8): {high_conf} ({high_conf/total*100:.1f}%)')
    print(f'   ä¸­ç½®ä¿¡åº¦ (0.5-0.8): {medium_conf} ({medium_conf/total*100:.1f}%)')
    print(f'   ä½ç½®ä¿¡åº¦ (<0.5): {low_conf} ({low_conf/total*100:.1f}%)')

    print(f'\nå»¶è¿Ÿç»Ÿè®¡ï¼š')
    print(f'   å¹³å‡å»¶è¿Ÿ: {avg_latency:.2f}ms')
    print(f'   P50 å»¶è¿Ÿ: {p50_latency:.2f}ms')
    print(f'   P95 å»¶è¿Ÿ: {p95_latency:.2f}ms')
    print(f'   ååé‡: {throughput:.2f} RPS')

    print(f'\næ··åˆ OCR ç­–ç•¥ç»Ÿè®¡ï¼š')
    print(f'   Qwen3-VL-Plus æˆåŠŸ: {qwen_success} ({qwen_success/total*100:.1f}%)')
    print(f'   PaddleOCR é™çº§: {paddle_fallback} ({paddle_fallback/total*100:.1f}%)')
    print(f'   é™çº§ç‡: {paddle_fallback/total*100:.2f}%')

    # é”™è¯¯åˆ—è¡¨
    if errors:
        print(f'\né”™è¯¯åˆ—è¡¨ ({len(errors)}):')
        for error in errors:
            print(f'   - {error["image"]}: {error["error"]}')

    # é”™è¯¯æ¡ˆä¾‹åˆ†æï¼ˆå‰10ä¸ªé”™è¯¯ï¼‰
    error_results = [r for r in results if not r['is_correct']]
    if error_results:
        print(f'\né”™è¯¯æ¡ˆä¾‹åˆ†æï¼ˆå‰10ä¸ªé”™è¯¯ï¼‰:')
        for i, r in enumerate(error_results[:10], 1):
            print(f'   {i}. {r["image"]}')
            print(f'      çœŸå®: {r["ground_truth"]}, é¢„æµ‹: {r["predicted"]}, ç½®ä¿¡åº¦: {r["confidence"]:.2f}, å»¶è¿Ÿ: {r["latency_ms"]:.0f}ms')

    # ä¿å­˜ç»“æœ
    if output_file:
        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)

        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump({
                'test_name': 'Hybrid OCR Stress Test (Qwen3-VL-Plus + PaddleOCR)',
                'timestamp': datetime.now().isoformat(),
                'config': {
                    'data_dir': data_dir,
                    'csv_file': csv_file,
                    'max_images': max_images,
                    'max_concurrent': max_concurrent,
                    'ocr_mode': 'hybrid',
                    'qwen_model': 'qwen3-vl-plus',
                    'confidence_threshold': 0.8
                },
                'total_images': total,
                'successful_tests': total - len(errors),
                'failed_tests': len(errors),
                'accuracy': accuracy,
                'correct_count': correct,
                'avg_latency_ms': avg_latency,
                'p50_latency_ms': p50_latency,
                'p95_latency_ms': p95_latency,
                'throughput_rps': throughput,
                'avg_confidence': avg_confidence,
                'high_confidence_count': high_conf,
                'medium_confidence_count': medium_conf,
                'low_confidence_count': low_conf,
                'qwen_success_count': qwen_success,
                'paddle_fallback_count': paddle_fallback,
                'qwen_api_fail_count': qwen_api_fail,
                'results': results,
                'errors': errors
            }, f, indent=2, ensure_ascii=False)

        print(f'\nâœ… ç»“æœå·²ä¿å­˜åˆ°: {output_path}')

    return {
        'total_images': total,
        'successful_tests': total - len(errors),
        'failed_tests': len(errors),
        'accuracy': accuracy,
        'correct_count': correct,
        'avg_latency_ms': avg_latency,
        'p50_latency_ms': p50_latency,
        'p95_latency_ms': p95_latency,
        'throughput_rps': throughput,
        'avg_confidence': avg_confidence,
        'high_confidence_count': high_conf,
        'medium_confidence_count': medium_conf,
        'low_confidence_count': low_conf,
        'qwen_success_count': qwen_success,
        'paddle_fallback_count': paddle_fallback,
        'qwen_api_fail_count': qwen_api_fail,
        'results': results,
        'errors': errors
    }


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='æ··åˆ OCR ç­–ç•¥å‹æµ‹')
    parser.add_argument('--data-dir', type=str,
                       default='/home/wlx/Aerovision-V1/data/',
                       help='æ•°æ®ç›®å½•')
    parser.add_argument('--csv-file', type=str,
                       default='/home/wlx/Aerovision-V1/data/labels.csv',
                       help='CSV æ ‡ç­¾æ–‡ä»¶')
    parser.add_argument('--max-images', type=int, default=100,
                       help='æœ€å¤§æµ‹è¯•å›¾ç‰‡æ•°')
    parser.add_argument('--max-concurrent', type=int, default=1,
                       help='æœ€å¤§å¹¶å‘æ•°')
    parser.add_argument('--output', type=str,
                       default='stress_test_hybrid_ocr_results.json',
                       help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')

    args = parser.parse_args()

    results = stress_test_hybrid_ocr(
        data_dir=args.data_dir,
        csv_file=args.csv_file,
        max_images=args.max_images,
        max_concurrent=args.max_concurrent,
        output_file=args.output
    )

    print(f'\nâœ… å‹æµ‹å®Œæˆï¼å‡†ç¡®ç‡: {results["accuracy"]*100:.2f}%')
    print(f'   Qwen3-VL-Plus æˆåŠŸ: {results["qwen_success_count"]} ({results["qwen_success_count"]/results["total_images"]*100:.1f}%)')
    print(f'   PaddleOCR é™çº§: {results["paddle_fallback_count"]} ({results["paddle_fallback_count"]/results["total_images"]*100:.1f}%)')

    sys.exit(0 if results['accuracy'] >= 0.9 else 1)


if __name__ == '__main__':
    main()
