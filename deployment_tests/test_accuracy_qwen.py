#!/usr/bin/env python3
"""
Qwen OCR å‡†ç¡®ç‡æµ‹è¯•
ä» /home/wlx/Aerovision-V1/data/labeled/ ä¸­å– 100 å¼ å›¾ç‰‡è¿›è¡Œæµ‹è¯•
çœŸå®æ³¨å†Œå·ä» CSV æ–‡ä»¶è¯»å–
"""

import os
import sys
import json
import time
import base64
import csv
from pathlib import Path
from collections import defaultdict

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))
sys.path.insert(0, str(Path(__file__).parent.parent.parent / "Aerovision-V1-inference"))

from PIL import Image
import io

# å¯¼å…¥ DashScope OCR å®¢æˆ·ç«¯
from dashscope_client import DashScopeOCRClient, DashScopeError


def load_ground_truth(csv_file: str) -> dict:
    """
    ä» CSV æ–‡ä»¶åŠ è½½çœŸå®æ³¨å†Œå·

    Args:
        csv_file: CSV æ–‡ä»¶è·¯å¾„

    Returns:
        dict: æ–‡ä»¶ååˆ°çœŸå®æ³¨å†Œå·çš„æ˜ å°„
    """
    ground_truth = {}
    try:
        with open(csv_file, 'r', encoding='utf-8-sig') as f:  # ä½¿ç”¨ utf-8-sig å¤„ç† BOM
            reader = csv.DictReader(f)
            # ç¡®å®šæ­£ç¡®çš„ filename é”®åï¼ˆè€ƒè™‘ BOMï¼‰
            filename_key = 'filename'
            if reader.fieldnames and '\ufeff' in reader.fieldnames[0]:
                filename_key = reader.fieldnames[0]

            for row in reader:
                filename = row.get(filename_key, '')
                registration = row['registration']
                ground_truth[filename] = registration
    except Exception as e:
        print(f"âš ï¸  æ— æ³•è¯»å– CSV æ–‡ä»¶: {e}")
        print(f"   å°†ä½¿ç”¨æ–‡ä»¶åè§£æä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆ")
        import traceback
        traceback.print_exc()
    return ground_truth


def run_accuracy_test(
    data_dir: str = "/home/wlx/Aerovision-V1/data/",
    csv_file: str = "/home/wlx/Aerovision-V1/data/labels.csv",
    max_images: int = 100,
    output_file: str = None
):
    """
    è¿è¡Œå‡†ç¡®ç‡æµ‹è¯•

    Args:
        data_dir: æµ‹è¯•å›¾ç‰‡æ ¹ç›®å½•
        csv_file: CSV æ ‡ç­¾æ–‡ä»¶
        max_images: æœ€å¤§æµ‹è¯•å›¾ç‰‡æ•°
        output_file: ç»“æœè¾“å‡ºæ–‡ä»¶
    """
    print("="*60)
    print("ğŸ§ª Qwen OCR å‡†ç¡®ç‡æµ‹è¯•")
    print("="*60)
    print(f"\n   æ•°æ®ç›®å½•: {data_dir}")
    print(f"   CSV æ–‡ä»¶: {csv_file}")
    print(f"   æµ‹è¯•å›¾ç‰‡æ•°: {max_images}")
    print()

    # æ£€æŸ¥ API Key
    api_key = os.getenv("DASHSCOPE_API_KEY")
    if not api_key:
        print("âŒ é”™è¯¯ï¼šDASHSCOPE_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®")
        return None

    # åŠ è½½çœŸå®æ ‡ç­¾
    print("ğŸ“‹ åŠ è½½çœŸå®æ ‡ç­¾...")
    ground_truth = load_ground_truth(csv_file)
    print(f"   åŠ è½½äº† {len(ground_truth)} æ¡æ ‡ç­¾")
    print()

    # åˆå§‹åŒ–å®¢æˆ·ç«¯
    try:
        print("ğŸ“ åˆå§‹åŒ– Qwen å®¢æˆ·ç«¯...")
        client = DashScopeOCRClient(
            model="qwen3.5-plus",  # ä½¿ç”¨ qwen3.5-plus æ¨¡å‹
            timeout=120  # å¢åŠ è¶…æ—¶æ—¶é—´åˆ° 120 ç§’
        )
        print("âœ… å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ\n")
    except DashScopeError as e:
        print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
        return None

    # è·å–æµ‹è¯•å›¾ç‰‡
    labeled_dir = Path(data_dir) / "labeled"
    if not labeled_dir.exists():
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°ç›®å½• {labeled_dir}")
        return None

    all_images = sorted(list(labeled_dir.glob("*.jpg")) + list(labeled_dir.glob("*.jpeg")))
    test_images = all_images[:max_images]

    print(f"ğŸ“· æ‰¾åˆ° {len(all_images)} å¼ å›¾ç‰‡")
    print(f"   æµ‹è¯• {len(test_images)} å¼ å›¾ç‰‡\n")

    # æµ‹è¯•ç»“æœ
    results = []
    latencies = []
    errors = []
    correct = 0
    total = 0
    high_conf = 0
    medium_conf = 0
    low_conf = 0
    accuracy = 0.0
    avg_latency = 0.0
    p50_latency = 0.0
    p95_latency = 0.0
    avg_confidence = 0.0

    # æµ‹è¯•æ¯å¼ å›¾ç‰‡
    for i, image_path in enumerate(test_images, 1):
        # ä» CSV è·å–çœŸå®æ³¨å†Œå·
        filename = image_path.name
        ground_truth_reg = ground_truth.get(filename, "")

        if not ground_truth_reg:
            print(f"[{i:3d}/{len(test_images)}] âš ï¸  {filename}")
            print(f"       è·³è¿‡ï¼šCSV ä¸­æ²¡æœ‰æ‰¾åˆ°çœŸå®æ ‡ç­¾")
            continue

        try:
            start_time = time.time()

            # åŠ è½½å›¾ç‰‡
            image = Image.open(image_path)
            if image.mode != "RGB":
                image = image.convert("RGB")

            # è°ƒç”¨ OCR
            result = client.recognize(image)

            latency = (time.time() - start_time) * 1000
            predicted = result["registration"]
            confidence = result["confidence"]

            # åˆ¤æ–­æ˜¯å¦æ­£ç¡®
            is_correct = predicted == ground_truth_reg
            if is_correct:
                correct += 1

            total += 1
            latencies.append(latency)

            # è®°å½•ç»“æœ
            results.append({
                "image": filename,
                "ground_truth": ground_truth_reg,
                "predicted": predicted,
                "is_correct": is_correct,
                "confidence": confidence,
                "latency_ms": latency
            })

            # æ˜¾ç¤ºè¿›åº¦
            status = "âœ“" if is_correct else "âœ—"
            print(f"[{i:3d}/{len(test_images)}] {status} {filename}")
            print(f"       çœŸå®: {ground_truth_reg}, é¢„æµ‹: {predicted}, ç½®ä¿¡åº¦: {confidence:.2f}, å»¶è¿Ÿ: {latency:.0f}ms")

        except DashScopeError as e:
            error_msg = str(e)
            errors.append({
                "image": filename,
                "ground_truth": ground_truth_reg,
                "error": error_msg
            })
            print(f"[{i:3d}/{len(test_images)}] âœ— {filename}")
            print(f"       é”™è¯¯: {error_msg}")

        except Exception as e:
            errors.append({
                "image": filename,
                "ground_truth": ground_truth_reg,
                "error": str(e)
            })
            print(f"[{i:3d}/{len(test_images)}] âœ— {filename}")
            print(f"       é”™è¯¯: {e}")

    # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
    if total > 0:
        accuracy = correct / total
        avg_latency = sum(latencies) / len(latencies) if latencies else 0
        p50_latency = sorted(latencies)[len(latencies) // 2] if latencies else 0
        p95_latency = sorted(latencies)[int(len(latencies) * 0.95)] if latencies else 0
        avg_confidence = sum(r["confidence"] for r in results) / len(results)

        # ç½®ä¿¡åº¦åˆ†å¸ƒ
        high_conf = sum(1 for r in results if r["confidence"] >= 0.8)
        medium_conf = sum(1 for r in results if 0.5 <= r["confidence"] < 0.8)
        low_conf = sum(1 for r in results if r["confidence"] < 0.5)

    print("\n" + "="*60)
    print("ğŸ“Š æµ‹è¯•ç»“æœ")
    print("="*60)

    if total > 0:
        print(f"\næ€»ä½“ç»Ÿè®¡ï¼š")
        print(f"   æ€»å›¾ç‰‡æ•°: {len(test_images)}")
        print(f"   æˆåŠŸè¯†åˆ«: {total}")
        print(f"   å¤±è´¥è¯†åˆ«: {len(errors)}")
        print(f"\nå‡†ç¡®ç‡æŒ‡æ ‡ï¼š")
        print(f"   è¯†åˆ«å‡†ç¡®ç‡: {accuracy:.4f} ({accuracy*100:.2f}%)")
        print(f"   æ­£ç¡®è¯†åˆ«æ•°: {correct}/{total}")
        print(f"\nç½®ä¿¡åº¦ç»Ÿè®¡ï¼š")
        print(f"   å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.4f}")
        print(f"   é«˜ç½®ä¿¡åº¦ (â‰¥0.8): {high_conf} ({high_conf/total*100:.1f}%)")
        print(f"   ä¸­ç½®ä¿¡åº¦ (0.5-0.8): {medium_conf} ({medium_conf/total*100:.1f}%)")
        print(f"   ä½ç½®ä¿¡åº¦ (<0.5): {low_conf} ({low_conf/total*100:.1f}%)")
        print(f"\nå»¶è¿Ÿç»Ÿè®¡ï¼š")
        print(f"   å¹³å‡å»¶è¿Ÿ: {avg_latency:.2f}ms")
        print(f"   P50 å»¶è¿Ÿ: {p50_latency:.2f}ms")
        print(f"   P95 å»¶è¿Ÿ: {p95_latency:.2f}ms")
        print(f"   ååé‡: {total/(sum(latencies)/1000):.2f} RPS")

    if errors:
        print(f"\né”™è¯¯åˆ—è¡¨ ({len(errors)}):")
        for err in errors[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
            print(f"   - {err['image']}: {err['error']}")
        if len(errors) > 10:
            print(f"   ... è¿˜æœ‰ {len(errors)-10} ä¸ªé”™è¯¯")

    # é”™è¯¯æ¡ˆä¾‹åˆ†æ
    if results:
        wrong_results = [r for r in results if not r["is_correct"]]
        if wrong_results:
            print(f"\né”™è¯¯æ¡ˆä¾‹åˆ†æï¼ˆå‰10ä¸ªé”™è¯¯ï¼‰ï¼š")
            for i, r in enumerate(wrong_results[:10], 1):
                print(f"   {i}. {r['image']}")
                print(f"      çœŸå®: {r['ground_truth']}, é¢„æµ‹: {r['predicted']}, ç½®ä¿¡åº¦: {r['confidence']:.2f}")

    # ä¿å­˜ç»“æœ
    if output_file:
        metrics = {
            "total_images": len(test_images),
            "successful_tests": total,
            "failed_tests": len(errors),
            "accuracy": accuracy if total > 0 else 0,
            "correct_count": correct,
            "avg_confidence": avg_confidence if results else 0,
            "high_confidence_count": high_conf,
            "medium_confidence_count": medium_conf,
            "low_confidence_count": low_conf,
            "avg_latency_ms": avg_latency if latencies else 0,
            "p50_latency_ms": p50_latency,
            "p95_latency_ms": p95_latency,
            "throughput_rps": total/(sum(latencies)/1000) if latencies else 0,
            "results": results,
            "errors": errors
        }

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(metrics, f, indent=2, ensure_ascii=False)

        print(f"\nâœ… ç»“æœå·²ä¿å­˜åˆ°: {output_file}")

    return {
        "accuracy": accuracy if total > 0 else 0,
        "total": total,
        "correct": correct,
        "errors": len(errors)
    }


def main():
    import argparse

    parser = argparse.ArgumentParser(description='Qwen OCR å‡†ç¡®ç‡æµ‹è¯•')
    parser.add_argument('--data-dir', default='/home/wlx/Aerovision-V1/data/', help='æµ‹è¯•æ•°æ®æ ¹ç›®å½•')
    parser.add_argument('--csv-file', default='/home/wlx/Aerovision-V1/data/labels.csv', help='CSV æ ‡ç­¾æ–‡ä»¶')
    parser.add_argument('--max-images', type=int, default=100, help='æœ€å¤§æµ‹è¯•å›¾ç‰‡æ•°')
    parser.add_argument('--output', default='accuracy_results_qwen.json', help='ç»“æœè¾“å‡ºæ–‡ä»¶ï¼ˆJSONæ ¼å¼ï¼‰')

    args = parser.parse_args()

    # è¿è¡Œæµ‹è¯•
    metrics = run_accuracy_test(
        data_dir=args.data_dir,
        csv_file=args.csv_file,
        max_images=args.max_images,
        output_file=args.output
    )

    if metrics and metrics["accuracy"] > 0:
        print(f"\nâœ… æµ‹è¯•å®Œæˆï¼å‡†ç¡®ç‡: {metrics['accuracy']*100:.2f}%")
    elif metrics:
        print(f"\nâš ï¸  æµ‹è¯•å®Œæˆï¼Œå‡†ç¡®ç‡: {metrics['accuracy']*100:.2f}%")

    return 0 if metrics else 1


if __name__ == "__main__":
    sys.exit(main())
